# 16. Sesgo de Confirmación y Escepticismo Organizado

No puedo dar a ningún científico, de cualquier edad, un mejor consejo que este: la intensidad de la convicción de que una hipótesis es verdadera no tiene relación con si realmente lo es. La importancia de la fuerza de nuestra convicción es únicamente proporcionar un incentivo proporcionalmente fuerte para averiguar si la hipótesis resistirá una evaluación crítica.
— Medawar, 1979, Advice to a Young Scientist

Ser científico es una carrera gratificante pero desafiante. Hacer ciencia puede conducir a la satisfacción intelectual de hacer descubrimientos o aumentar nuestra comprensión sobre cuestiones importantes, a la sensación gratificante de contribuir a soluciones para problemas relevantes que enfrenta la sociedad, a interactuar con colegas estimulantes, al reconocimiento de pares y del público en general, así como a la posibilidad de obtener un ingreso decente si te conviertes en un experto internacionalmente solicitado en tu campo. Al mismo tiempo, puede ser una carrera difícil que requiere mucho trabajo, incertidumbre sobre tu futuro profesional, momentos en los que se logra poco avance en el conocimiento, competitividad o incluso animosidad hacia otros científicos, y una sensación constante de presión por alcanzar metas (National Academy of Sciences et al., 2009).

Aunque la ciencia es un esfuerzo colectivo, los científicos a menudo tienen un fuerte compromiso personal con su trabajo. Están motivados para tener éxito, y se sienten decepcionados si su trabajo no lo logra.

En su libro “La ciencia moderna y la naturaleza de la vida”, William Beck (1957) escribe: Cada paso sucesivo en el método científico exige una mayor inversión emocional y añade dificultad a mantenerse objetivo. Cuando el ego está implicado, la autocrítica puede ser difícil (¿quién ha oído hablar de dos científicos compitiendo para demostrar que el otro tiene razón?). Siempre se tiene un interés personal en que el resultado sea exitoso y, nos guste admitirlo o no, cada uno de nosotros siente la presión de tener éxito, de abrir 'nuevos caminos' quizás antes de haber dominado los anteriores. Es evidente, por tanto, cómo las tendencias neuróticas latentes pueden influir y distorsionar los mandatos puros del método científico, y generar error, valores poco realistas, ansiedad y —seamos sinceros, dado que la ciencia se realiza a puerta cerrada— deshonestidad. Como los científicos son humanos y la ciencia no lo es, como en todos los campos, el fino hilo de la integridad a veces se tensa hasta el punto de romperse.

El reconocimiento de que la ciencia es una actividad humana no ha pasado desapercibido. En 1620, Francis Bacon escribió el libro *Novum Organum* (o *Nuevo Método*), que proporcionó una primera descripción de un método científico moderno, centrado en el empirismo y el razonamiento inductivo. Bacon ya comprendía, hace más de 400 años, que las personas no son observadoras pasivas, y ofrece una descripción muy temprana de lo que hoy llamaríamos sesgo de confirmación: El entendimiento humano, una vez que se ha planteado una proposición (ya sea por aceptación general y creencia, o por el placer que proporciona), fuerza todo lo demás a añadir apoyo y confirmación; y aunque puedan existir ejemplos abundantes y convincentes en sentido contrario, no los observa o los desprecia, o los descarta con alguna distinción, con prejuicio violento e injusto, antes que sacrificar la autoridad de sus primeras conclusiones. Bien respondió quien, al ser mostrado en un templo las tablillas votivas colgadas por quienes escaparon del naufragio, preguntó si entonces se debía reconocer el poder de los dioses, inquiriendo: “¿Y dónde están los retratos de quienes perecieron a pesar de sus votos?”. Toda superstición es bastante similar, ya se trate de astrología, sueños, presagios, juicios retributivos o cosas parecidas, en todas las cuales los creyentes engañados observan los eventos que se cumplen, pero descuidan y omiten los fallos, aunque sean mucho más comunes. Pero este mal se insinúa aún más astutamente en la filosofía y las ciencias, en las cuales una máxima establecida vicia y gobierna todas las demás circunstancias, aunque estas últimas sean mucho más dignas de confianza. Además, incluso sin esa prisa y falta de reflexión (que ya hemos mencionado), es el error peculiar y perpetuo del entendimiento humano el sentirse más movido y excitado por afirmaciones que por negaciones, cuando en realidad debería ser imparcial. De hecho, para establecer un verdadero axioma, la instancia negativa es la más poderosa.

En un artículo clásico sobre el sesgo de confirmación, Nickerson (1998) lo define como: La búsqueda o interpretación de evidencia de maneras que favorecen las creencias existentes, expectativas o una hipótesis mantenida.

Los factores humanos que influyen (o sesgan) la generación del conocimiento científico han recibido relativamente poca atención por parte de los filósofos de la ciencia, aunque sería ingenuo creer que los científicos persiguen objetivamente la verdad. Como escribe el filósofo de la ciencia Chang (2022): Existe una tendencia en la filosofía de la ciencia a presentar al científico como un ser fantasmal que simplemente tiene grados de creencia en varias afirmaciones descriptivas, las cuales se ajustan según ciertas reglas del pensamiento racional (por ejemplo, el teorema de Bayes), eliminando así cualquier necesidad de juicio real. Todo lo que no encaja en esta visión extraña y empobrecida, tendemos a denigrarlo como asuntos de ‘mera’ psicología o sociología.

El sociólogo de la ciencia Robert Merton (1942) creía que cuatro conjuntos de imperativos institucionales —universalismo, comunismo, desinterés y **escepticismo organizado**— conforman el *ethos* de la ciencia moderna.

* **Universalismo** significa que “la aceptación o el rechazo de afirmaciones que entran en el ámbito de la ciencia no debe depender de las características personales o sociales de quien las propone”.
* **Comunismo** significa que “los hallazgos sustantivos de la ciencia son producto de la colaboración social y se asignan a la comunidad”. Los científicos no son dueños de sus teorías; en el mejor de los casos, reciben reconocimiento por desarrollarlas. Como escribe Merton: “El secreto es la antítesis de esta norma; la comunicación plena y abierta es su aplicación”.
* **Desinterés** no ocurre a nivel individual —un científico puede tener pasiones y motivaciones— sino a nivel institucional. La institución de la ciencia tiene como norma el desinterés, lo que significa que las afirmaciones deben ser veraces y no engañosas. Según Merton, los científicos están sometidos a una vigilancia rigurosa: son responsables ante sus pares, quienes revisarán su trabajo, y por lo tanto, solo el desinterés conducirá a afirmaciones que sobrevivan al escrutinio.
* **Escepticismo organizado** significa el “escrutinio de las creencias en términos de criterios empíricos y lógicos”. Las afirmaciones solo se aceptan después de haber sobrevivido al examen por parte de colegas.

Como ocurre con cualquier norma, no todos los individuos la suscriben completamente y, más importante aún, no todos se comportan de acuerdo con ellas (al menos no todo el tiempo). Este es el patrón que Anderson y colegas (2007) encontraron en una encuesta realizada a científicos de EE. UU.. Los científicos suscriben las normas mertonianas (la puntuación máxima posible es 12). También admiten que no siempre siguen estas normas en su propio comportamiento, y creen que otras personas aún las siguen menos. El patrón es opuesto en el caso de las contranormas (por ejemplo, el secretismo, el interés personal, etc.).



*Figura 1: Promedios de adhesión normativa y contranormativa, y comportamiento según Anderson et al. (2007).*

Cuando se les pregunta, los científicos no consideran que los miembros de su propia profesión sean completamente objetivos. En una interesante serie de entrevistas a científicos involucrados en el alunizaje del Apolo, Mitroff (1974) concluyó: Cada uno de los científicos entrevistados en la primera ronda de entrevistas indicó que pensaba que la noción del científico objetivo y emocionalmente desinteresado era ingenua. Su artículo está lleno de citas excelentes que ilustran esta conclusión, como por ejemplo: Científico B: El científico no implicado y sin emociones es tan ficticio como el científico loco que destruirá el mundo por conocimiento. La mayoría de los científicos que conozco tienen teorías y están buscando datos que las respalden; no están examinando los datos de forma impersonal en busca de una teoría que se ajuste a ellos. Hay que hacer una clara distinción entre no ser objetivo y hacer trampa. Un buen científico no se negará a cambiar su teoría si encuentra una gran cantidad de evidencia que no la apoya, pero en esencia, está intentando defenderla. Sin compromiso [emocional], uno no tendría la energía ni el impulso para seguir adelante, a veces contra obstáculos extremadamente difíciles. No falsificas conscientemente la evidencia en ciencia, pero le das menos importancia a un dato que te contradice. Ningún científico respetable hace esto conscientemente, pero sí lo haces de forma subconsciente. Científico G: Cada idea científica necesita un representante personal que la defienda y la nutra, para que no sufra una muerte prematura.

Estas entrevistas revelan que los científicos creen que el compromiso con una idea o teoría específica es necesario si se quiere tener la motivación para seguir explorándola. En otras palabras, el sesgo de confirmación incluso podría tener un papel positivo que desempeñar.

Investigadoras e investigadores en campos como la psicología de la ciencia, la sociología de la ciencia y la metaciencia intentan describir las formas en que quienes investigan caen víctimas del sesgo de confirmación. Por ejemplo, Mahoney (1979) concluyó que: El científico no es inmune a los sesgos perceptivos y con frecuencia reacciona con bastante emotividad ante cuestiones técnicas y epistemológicas. Aún está por demostrarse que los científicos sean más lógicos que quienes no lo son en la realización e interpretación de su trabajo. El científico puede, a veces, mostrarse poco receptivo a datos relevantes y —particularmente en el caso de quienes desarrollan teorías— propenso a especulaciones apresuradas y a una tenacidad dogmática. Informes sobre fabricación de datos y sesgo del experimentador sugieren que tales fenómenos no son ni raros ni triviales. Los científicos tienden a ser reservados y desconfiados hasta que logran establecer públicamente la prioridad de sus hallazgos.

Entonces, ¿por qué la ciencia parece seguir funcionando, a pesar de todas estas limitaciones tan humanas? Una manera de entenderlo es considerar la ciencia como un método que usan los grupos de personas para hacer afirmaciones, aplicando procedimientos destinados a reducir el rol del sesgo de confirmación. Aunque la ciencia abarca mucho más que un conjunto de reglas para evitar este sesgo, muchas prácticas —como la revisión por pares, la realización de estudios de replicación independientes o la especificación del nivel alfa antes de observar los datos— solo se entienden desde esta perspectiva.

Algunas y algunos científicos consideran los esfuerzos activos por resistir el sesgo de confirmación como una característica esencial de una buena práctica científica. Como dijo Feynman: El primer principio es que no debes engañarte a ti mismo —y tú eres la persona más fácil de engañar.
— Feynman (1974)

## 16.1. Sesgo de confirmación en la Ciencia

Wason (1960) creó una tarea sencilla para examinar cómo las personas ponen a prueba hipótesis. En la tarea, se recibe una serie de tres números (ej., 2, 4, 8) y la tarea es desarrollar una hipótesis sobre la regla subyacente que ha generado esos tres números. Para probar la hipótesis, se sugiere un nuevo conjunto de tres números, y se informa si sigue o no la regla.

Si se proponen los números 3, 6, 12, se sigue la regla “el primer número se duplica, y luego se vuelve a duplicar”. Sin embargo, la regla real que había que descubrir era: “tres números en orden creciente de magnitud”.

Como la mayoría de personas que realizan esta tarea, probablemente se probó un conjunto de tres números que confirmaban la regla que se tenía en mente. Que la regla sea confirmada te dice que puede ser correcta, pero no descarta que muchas otras reglas también lo sean. En cambio, si se prueba un conjunto de números que crees que no seguirán la regla, como por ejemplo 1, 2, 3, y descubres que sí la siguen, eso te indica con certeza que tu regla original era incorrecta.

Confirmar y refutar predicciones es igualmente importante, pero en general las personas tienden menos a intentar demostrarse que están equivocadas. Este conocimiento sobre la psicología humana es útil, porque nos permite desarrollar métodos y procedimientos que contrarresten los efectos negativos de nuestra inclinación a querer confirmar nuestras hipótesis.

En su artículo titulado “Ciencia Patológica”, Langmuir (1989) discute ejemplos de sesgo de confirmación en física, como el efecto Davis-Barnes y el caso de los rayos N. En ambos casos, el escepticismo llevó a inspecciones presenciales de los experimentos, concluyendo que los resultados se debían a errores del observador. “Estos son casos donde no hay deshonestidad, pero donde las personas se dejan engañar por una falta de comprensión sobre lo que los seres humanos pueden hacerse a sí mismos: ser conducidos al error por efectos subjetivos, pensamiento ilusorio o interacciones en el umbral perceptual”.

A veces, las y los científicos cometen fraude científico deliberado y fabrican datos. Pero no siempre está claro dónde trazar la línea entre el sesgo intencional y el no intencional. Por ejemplo, en el caso del genetista Gregor Mendel, reanálisis posteriores de sus datos por Ronald Fisher revelaron que sus resultados eran sospechosamente cercanos a los resultados esperados (Fisher, 1936). Aunque se coincide en que los resultados son estadísticamente inverosímiles, la causa exacta es difícil de identificar. Una de las razones para adoptar prácticas de ciencia abierta es que la comunidad científica se beneficiaría de una mayor transparencia sobre lo que ocurrió en situaciones donde surgen dudas sobre la validez de los resultados.

No solo las y los científicos fabrican datos: el alumnado también lo hace. En intentos de replicar un estudio como tarea de clase, Azrin y colegas (1961) encontraron que muchas y muchos estudiantes fabricaron total o parcialmente los datos porque seguir el procedimiento experimental era demasiado difícil. En un caso, 12 de 19 estudiantes admitieron inmediatamente haber fabricado datos. Podemos imaginar muchas razones por las que el alumnado fabricaría datos: no querer admitir que fallaron o simplemente para evitar hacer el trabajo real.

El código de conducta para la integridad en la investigación se aplica tanto al profesorado como al alumnado. Siempre que sientas presión y te veas tentado a violar este código (por ejemplo, fabricando datos), ¡no lo hagas! En su lugar, informa del problema a una o un docente, o a una persona asesora confidencial si te resulta más cómodo.

A menudo no está claro en qué medida son conscientes de lo problemático del uso oportunista de la flexibilidad de los métodos para aumentar la probabilidad de encontrar apoyo a sus hipótesis. Kish (1959) ya había mencionado uno de los usos incorrectos de las pruebas estadísticas: “Primero, está el 'disparo con escopeta' en busca de diferencias significativas”. Estas preocupaciones solo recibieron una atención amplia en psicología al comienzo de la crisis de replicación, por ejemplo, a través del artículo “False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant” (Simmons et al., 2011).

Un mecanismo final mediante el cual opera el sesgo de confirmación es el conocido como **sesgo de citación**, donde las autoras y autores seleccionan investigaciones que respaldan sus afirmaciones, mientras ignoran evidencia que las contradice. El sesgo de citación puede prevenirse adoptando prácticas como:

* Leer siempre los artículos que se citan.
* Buscar de forma sistemática en la literatura, en lugar de confiar únicamente en los artículos más citados que aparecen en los primeros resultados de Google Scholar.

El sesgo de citación también puede usarse de forma activa para hacer que un artículo científico parezca más convincente para quienes lo leen. Corneille et al. (2023) mencionan este truco junto a una lista de otras estrategias que algunas personas investigadoras utilizan para que sus afirmaciones suenen más sólidas de lo que realmente son. Esto incluye:

* Citar trabajos débiles o que ya se sabe que son erróneos.
* Hacer afirmaciones no respaldadas por evidencia.
* Generalizar más allá de lo que los datos realmente permiten.
* Seleccionar citas de forma parcial o sacarlas de contexto.
* Minimizar las limitaciones del estudio.

## 16.2. Escepticismo Organizado

Existen diversas prácticas en la ciencia cuyo propósito es contrarrestar, en la medida de lo posible, los sesgos, permitiendo que las afirmaciones sean sometidas a un escrutinio crítico.

### 16.2.1 Control de errores

William Gosset (Student, del test *t* de Student) reconocía que era útil especificar de forma objetiva la tasa de error que se va a utilizar para sacar conclusiones, dado que: “...es generalmente aceptado que dejar el rechazo de experimentos totalmente a discreción de quien los realiza es peligroso, ya que puede estar sesgado. Por ello, se ha propuesto adoptar un criterio que dependa de la probabilidad de que ocurra un error tan amplio en el número de observaciones dado.”

El uso de un nivel alfa fijo (por ejemplo, 0.05 en muchos campos) es un ejemplo claro de escepticismo organizado. Las afirmaciones deben pasar un criterio que controle las conclusiones erróneas antes de tomarse en serio.

### 16.2.2 Prerregistro

Una persona investigadora puede usar un nivel alfa fijo antes de observar los datos, pero eso no es suficiente para controlar conclusiones erróneas si, posteriormente, elige el test que desea aplicar tras haber identificado patrones interesantes. La solución a este problema es el prerregistro del plan de análisis.

El prerregistro es una forma de escepticismo organizado. En lugar de confiar ciegamente en que las personas reporten de forma imparcial sus análisis planificados, se les pide que usen un método de evaluación de hipótesis en el que sus pares puedan verificar si esos análisis fueron efectivamente definidos antes de tener acceso a los datos.

### 16.2.3 Estudios de replicación independiente

Después de que se ha realizado un estudio y se ha alcanzado una conclusión, el siguiente paso crítico es que otras personas intenten replicar de forma independiente ese hallazgo. La replicación independiente proporciona un método para explorar hasta qué punto errores o sesgos del estudio original causaron un efecto.

Si un hallazgo puede ser replicado de forma independiente por otras personas, es menos probable que la afirmación original esté influida por:

* Características sutiles del estudio inicial.
* Problemas más graves, como fraude o una tasa inflada de errores tipo I debido a flexibilidad en el análisis de datos.

### 16.2.4 Revisión por pares

El ejemplo prototípico de escepticismo organizado en la ciencia es el proceso de revisión por pares. La crítica desde puntos de vista alternativos es necesaria para la objetividad y es lo que limita la intrusión de preferencias subjetivas individuales en el conocimiento científico.

* La revisión por pares suele ser **anónima**. Los investigadores a menudo afirman que firmar las revisiones dificultaría ser honestos cuando creen que un manuscrito es de baja calidad.
* El anonimato tiene inconvenientes, ya que es posible que las personas revisoras hagan todo lo posible para evitar que ciertos resultados lleguen a publicarse.
* El proceso determina si un artículo se publica o no, pero la **calidad** de la revisión por pares es tan buena como quienes revisan.

La revisión por pares cumple un papel importante, pero no se puede asumir que todos los manuscritos revisados por pares estén libres de errores o afirmaciones incorrectas. La revisión por pares post-publicación, como en plataformas como PubPeer, ha revelado con frecuencia errores que las revisiones originales pasaron por alto.

### 16.2.5 Revisión de errores

Los errores en la investigación ocurren, y son más probables cuando respaldan lo que esperábamos encontrar. Rosenthal (1966) ofrece una revisión de varios estudios donde se cometieron errores al registrar las respuestas de participantes, y esos errores iban en la dirección esperada por las hipótesis.

### 16.2.6 El método de las hipótesis múltiples

T. C. Chamberlin observaba cómo las personas científicas tienden a desarrollar afecto hacia sus propias teorías, lo que lleva a una selección y ensalzamiento inconscientes de los fenómenos que armonizan con la teoría.

Para evitar este sesgo afectivo, Chamberlin propuso el **método de las hipótesis múltiples**:

* Se deben desarrollar **varias hipótesis plausibles** para explicar un fenómeno, sin otorgar a ninguna un estatus preferente.
* De esta manera, se puede examinar con más objetividad cuál de ellas está mejor sustentada por los datos.
* Quien investiga se convierte en "madre o padre de una familia de hipótesis: y, por su relación parental con todas ellas, se le prohíbe encariñarse demasiado con ninguna en particular".

### 16.2.6 La persona abogada del diablo

La **persona abogada del diablo** es quien asume el papel de escéptica y argumenta contra la posición aceptada o deseada. La idea es asignar explícitamente ese rol dentro de un grupo para expresar críticas activamente, contrarrestando la presión por conformarse.

## 16.3. Conclusión

La ciencia es una empresa profundamente humana. Quienes investigan tienen motivaciones y deseos que pueden sesgar las afirmaciones que hacen. Sin embargo, existen prácticas a nivel individual e institucional que permiten limitar la influencia de estos sesgos.

Es crucial estar atentas y atentos al papel que juega el sesgo de confirmación en la ciencia, y aplicar las estrategias descritas en este capítulo para no caer en sus trampas. El primer principio es que no debes engañarte a ti mismo —y tú eres la persona más fácil de engañar (Feynman, 1974).

* El **trabajo en colaboración** dentro de un equipo de investigación puede actuar como una capa de protección.
* Los errores también pueden prevenirse con herramientas como los **manuscritos computacionalmente reproducibles**, que evitan errores de copiar y pegar (Rouder et al., 2019; Strand, 2023).
